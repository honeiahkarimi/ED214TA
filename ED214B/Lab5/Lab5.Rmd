---
title: 'Lab 5: ANOVA with Categorical Predictors'
author: "ED 214B"
date: "Winter 2024"
output: 
  prettydoc::html_pretty:
    theme: hpstr
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, fig.align = 'center', out.width="75%")

setwd("~/Desktop/ED214_TA_Materials/ED214B/Lab5")
```

## Importing Necessary Packages

```{r}
library(readr) # importing csv file
library(emmeans) # estimated marginal means
library(DescTools) # post hoc test
library(summarytools) # freq
library(psych) # describeBy
library(tidyverse) # ggplot
```

## Importing the Dataset

```{r}
df <- read_csv("Labdata.csv")
View(df)
```

## Introduction to Dummy Coding

To use a categorical predictor with more than 2 levels in a regression model, we need to recode the variable into multiple variables to create a *reference* category. It is most common (and easiest) to use a method called "dummy coding". We can think of dummy coding as creating a bunch of dichotomous variables, where 0 is always the same reference category throughout.

## Regression with One Categorical Predictor with 3+ Levels

Our predictor variable will be Political Party (**Party**) and our outcome variable will be Voter Likelihood (**Likelihood**). Let's see which party is the most likely to vote in an election!

### Creating the Dummy Variables

The first thing we need to do is create dummy variables. Let's begin by running the frequencies for this variable to see how many dummy variables we need to create (and make sure we have no missing data). The *% valid* column refers to the *% of all non-missing*.

```{r}
freq(df$Party)
```
- 1: Democrat
- 2: Republican
- 3: Independent

There are three categories, so we need two dummy variables.  Let's make **Independent** our reference category.  This means we need to create two dummy variables: one for Democrat, and one for Republican.  

### Recoding

Let's use a function called `mutate` from the tidyverse to create two new variables.  We'll use the `ifelse` function to tell R that we want the dummy variable to have a value of **1** if the person is a member of that category and **0** if the person is not a member of that category

```{r}
df <- df %>% 
  mutate(Democrat=ifelse(Party==1,1,0),
         Republican=ifelse(Party==2,1,0))
```

**How can we double check that we created this dummy variable correctly?**

```{r}
xtabs(~Party+Democrat, data=df)
xtabs(~Party+Republican, data=df)
```

**As we see in the table above, we've successfully created two dummy variables:**

- Democrat: 1's for Democrats, 0's for Independents and Republicans
- Republican: 1's for Republicans, 0's for Independents and Democrats

### Our Multiple Linear Regression Model

Now, let's run the regression model with these two dummy variables to see which political party members are most likely to vote in the election.

```{r}
MLR <- lm(Likelihood~Democrat+Republican, data=df)
summary(MLR)
```

$$\hat{y}=51.981-13.357*{d_{dem}}-7.780*{d_{rep}}$$
- So, how likely are independents to vote in the election?

$$\hat{y}=51.981-(13.357*0)-(7.780*0)$$
$$\hat{y}=51.981$$
- How likely are democrats to vote in the election?

$$\hat{y}=51.981-(13.357*1)-(7.780*0)$$
$$\hat{y}=38.624$$
- How likely are republicans to vote in the election?

$$\hat{y}=51.981-(13.357*0)-(7.780*1)$$
$$\hat{y}=44.201$$

#### Are democrats significantly less likely to vote in the election than independents?
  - Yes, because *p* < .001
  
#### Are republicans significantly less likely to vote in the election than independents?
  - Yes, because *p* < .001

#### Are democrats significantly less likely to vote in the election than republicans?
  - **We do not know, because we can only compare each dummy variable to the reference category**
  - To test this, you would need to change the reference category to republican (or democrat) and then compare the democrat (or republican) dummy variable to the reference category
  
## Our ANOVA model

ANOVA models are helpful because they use a type of coding called effects coding, which allows us to compare **all** of the groups with each other. Let's replicate this problem using an ANOVA model so that we can compare all of the groups. The ANOVA model gives us the omnibus F-test ("Is there a significant difference anywhere in the model?") and we can then use post hoc tests to compare the group means.  We'll use a Type I error correction so that our Type I error rate does not exceed .05.

We begin by making a Party a factor variable and telling R what each category stands for.  Check your dataframe to see how this variable changed.

```{r}
# this c means this is a vector
df$Party<-factor(df$Party,
                    levels=c(1,2,3),
                    labels=c("Democrat","Republican","Independent"))
```

Now, let's run the ANOVA model to see if at least one political party is significantly more or less likely to vote than another (in other words, is there a significant difference anywhere in the model?).  Note that we already know that there is a significant difference because the ANOVA model is just a special case of a regression model when all of the predictors are categorical, and we already ran the regression model.

```{r}
model <- aov(Likelihood~Party, data=df)
summary(model)
```

Now, let's compute posthoc tests to see which political parties are significantly different from each other.  We'll use a Tukey-HSD (Honestly Significant Difference) Type I error correction. This post-hoc test looks at "family-wise error", which represents the probability that the significance tests is a Type I error (false positive).

```{r}
# the two colons means we are specifying which package the function is from
DescTools::PostHocTest(model, method="hsd")
```

We can now see that the voting likelihoods of all of the political parties are significantly different from each other.

What can use the emmeans function to get the **estimated marginal means**.  Marginal means are the model predicted means for each group, controlling for other variables in the model.  In this case, there are no other variables in the model so the marginal means are the actual means.  We want to use the marginal means because we are creating a "model" for a reason - we are trying to estimate the population parameters and we do not want to report sample dependent estimates. 

```{r}
emmeans::emmeans(model, ~Party)
```

These results will be identical to the means for each group from the describeBy function from the psych package *when there is only one predictor variable*.

```{r}
describeBy(df$Likelihood, df$Party)
```

```{r}
describe(df$Likelihood)
```

And we can use the the emmip function to plot the estimated marginal means and visualize the differences.

```{r}
emmip(model,~Party)
```

**How do we interpret this in APA format?**

A one-way ANOVA was conducted to compare the effect of political party membership (Independent/Republican/Democrat) on voter likelihood.  Voter likelihood was calculated using responses to a survey about voter likelihood (M = 44.44, SD = 14.19, min = 4.07, max = 92.88; see Figure 1 below).  There was a significant effect of political party membership on voter likelihood $[F(2,497)=40.88, p < .001]$. Post hoc comparisons using a Tukey-HSD correction revealed significant differences between all three political parties at the .001 alpha level. Independents were the most likely to vote (M = 52.0) followed by Republicans (M = 44.2) and Democrats (M = 38.6; see Figure 2 below).

```{r}
ggplot(df, aes(x=Likelihood))+
  geom_histogram()+
  theme_classic()+
  labs(y="Number of Participants",x="Likelihood of voting", title = "Figure 1")
```

```{r}
emmip(model, ~Party, CIs=TRUE)+
  labs(x="Political Party", y = "Voter Likelihood Marginal Mean", title="Figure 2")+
  ylim(0,100)+
  theme_classic()
```

**Note**: Figure 2 is the same as the marginal means plot but with a rescaled y-axis.
